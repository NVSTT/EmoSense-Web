import json
import re
from transformers import pipeline
from model.ollama import OllamaClient

def analyze_sentiment(text: str, choose: bool, ollama_client: OllamaClient) -> dict:
    if choose:
        prompt = f"""–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —ç–º–æ—Ü–∏–π –≤ —Ç–µ–∫—Å—Ç–∞—Ö, –≤–∫–ª—é—á–∞—è –ø–æ—ç–∑–∏—é –∏ —Å–ª–æ–∂–Ω—ã–µ —Å–ª—É—á–∞–∏.
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –≥–ª—É–±–æ–∫–æ –∏ –ø–æ–¥—Ä–æ–±–Ω–æ.
        –û–ø—Ä–µ–¥–µ–ª–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–µ–π: positive, negative, neutral (—Å—É–º–º–∞ = 1.0).
        –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON –æ–±—ä–µ–∫—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ: {{"positive": 0.XX, "negative": 0.XX, "neutral": 0.XX}}

        –¢–µ–∫—Å—Ç: {text}"""

        raw_response = ollama_client.generate(prompt, max_tokens=80, temperature=0.3)
        scores = {"positive": 0.33, "negative": 0.33, "neutral": 0.34}
        sentiment = "neutral"

        if raw_response:
            json_match = re.search(r'\{.*\}', raw_response, re.DOTALL)
            if json_match:
                try:
                    parsed = json.loads(json_match.group())
                    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤—Å–µ –∫–ª—é—á–∏ –Ω–∞ –º–µ—Å—Ç–µ –∏ –∑–Ω–∞—á–µ–Ω–∏—è ‚Äî —á–∏—Å–ª–∞
                    if all(k in parsed for k in ['positive', 'negative', 'neutral']):
                        scores = {
                            'positive': float(parsed['positive']),
                            'negative': float(parsed['negative']),
                            'neutral': float(parsed['neutral'])
                        }
                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º (–Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ —Å—É–º–º–∞ ‚â† 1)
                        total = sum(scores.values())
                        if total > 0:
                            scores = {k: v / total for k, v in scores.items()}
                        sentiment = max(scores, key=scores.get)
                except (json.JSONDecodeError, ValueError, TypeError):
                    pass  # –æ—Å—Ç–∞–≤–∏—Ç—å fallback

    else:
        try:
            pipe = pipeline(
                "text-classification",
                model="blanchefort/rubert-base-cased-sentiment-rusentiment",
                return_all_scores=True
            )
            results = pipe(text)[0]
            scores = {}
            for res in results:
                label = res['label'].lower()
                if label in ['positive', 'negative', 'neutral']:
                    scores[label] = res['score']
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–ª–∞—Å—Å—ã –Ω—É–ª—è–º–∏
            for label in ['positive', 'negative', 'neutral']:
                if label not in scores:
                    scores[label] = 0.0
            sentiment = max(scores, key=scores.get)
        except Exception as e:
            print(f"RuBERT error: {e}")
            scores = {"positive": 0.33, "negative": 0.33, "neutral": 0.34}
            sentiment = "neutral"

    return {"sentiment": sentiment, "scores": scores}


def generate_ai_comment_with_ollama(post_text: str, sentiment: str, ollama_client: OllamaClient) -> str:
    prompt = f"""–¢—ã ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –±–æ—Ç –≤ —Å–æ—Ü—Å–µ—Ç–∏. –ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π, —Ç—ë–ø–ª—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –ø–æ—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —Ç–æ–º –∂–µ —è–∑—ã–∫–µ, —á—Ç–æ –∏ –ø–æ—Å—Ç.
    (1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –º–∞–∫—Å–∏–º—É–º 15 —Å–ª–æ–≤. –ù–µ —É–ø–æ–º–∏–Ω–∞–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å.)

    –ü–æ—Å—Ç: "{post_text}" """
    
    raw_comment = ollama_client.generate(prompt, max_tokens=50, temperature=0.8)
    comment = raw_comment
    return comment or "ü§ñ –ò–ò –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."

def generate_sentiment_explanation(post_text: str, sentiment: str, ollama_client: OllamaClient) -> str:
    prompt = f"""–û—Ç–≤–µ—á–∞–π –Ω–∞–ø—Ä—è–º—É—é.
    –û–±—ä—è—Å–Ω–∏ –∫—Ä–∞—Ç–∫–æ (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), –ø–æ—á–µ–º—É —Ç–µ–∫—Å—Ç –∏–º–µ–µ—Ç —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å "{sentiment}".
    –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —Ç–æ–º –∂–µ —è–∑—ã–∫–µ, —á—Ç–æ –∏ —Ç–µ–∫—Å—Ç.

    –¢–µ–∫—Å—Ç: "{post_text}" """
    
    raw_explanation = ollama_client.generate(prompt, max_tokens=100, temperature=0.5)
    explanation = raw_explanation
    return explanation or "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ—è—Å–Ω–µ–Ω–∏–µ."

def generate_full_reasoning(post_text: str, scores: dict, ollama_client: OllamaClient) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥—Ä–æ–±–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –ò–ò: –∫–∞–∫–∏–µ —ç–º–æ—Ü–∏–∏ –¥–æ–º–∏–Ω–∏—Ä—É—é—Ç, –ø–æ—á–µ–º—É,
    —Å –∞–Ω–∞–ª–∏–∑–æ–º –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
    """
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
    prob_str = ", ".join([f"{k}: {v:.1%}" for k, v in scores.items()])
    
    prompt = f"""–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —ç–º–æ—Ü–∏–π –≤ —Ç–µ–∫—Å—Ç–∞—Ö, –≤–∫–ª—é—á–∞—è –ø–æ—ç–∑–∏—é –∏ —Å–ª–æ–∂–Ω—ã–µ —Å–ª—É—á–∞–∏.
    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –≥–ª—É–±–æ–∫–æ –∏ –ø–æ–¥—Ä–æ–±–Ω–æ.

    –¢–µ–∫—Å—Ç: "{post_text}"

    –†–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–¥–µ–ª–∏: {prob_str}

    –ù–∞–ø–∏—à–∏ —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ (3‚Äì5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–µ –±–æ–ª—å—à–µ):
    - –ö–∞–∫–∏–µ –∏–º–µ–Ω–Ω–æ —Å–ª–æ–≤–∞, –æ–±—Ä–∞–∑—ã –∏–ª–∏ —Ñ—Ä–∞–∑—ã –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –æ–∫—Ä–∞—Å–∫—É?
    - –ü–æ—á–µ–º—É –¥–æ–º–∏–Ω–∏—Ä—É–µ—Ç –∏–º–µ–Ω–Ω–æ —ç—Ç–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å?
    - –£—á—Ç–∏ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –∏—Ä–æ–Ω–∏—é, —Å–∞—Ä–∫–∞–∑–º, –º–µ–ª–∞–Ω—Ö–æ–ª–∏—é, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å.
    - –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –ø—Ä–æ—Å—Ç–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ ‚Äî –æ–±—ä—è—Å–Ω–∏ —Å–º—ã—Å–ª.

    –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —Ç–æ–º –∂–µ —è–∑—ã–∫–µ, —á—Ç–æ –∏ —Ç–µ–∫—Å—Ç."""
    
    raw_reasoning = ollama_client.generate(prompt, max_tokens=350, temperature=0.6)
    return raw_reasoning or "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑."